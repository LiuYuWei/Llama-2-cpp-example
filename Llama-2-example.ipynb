{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bba801bf",
   "metadata": {},
   "source": [
    "# Llama 2 Introduction\n",
    "\n",
    "#### Made by SimonLiu\n",
    "\n",
    "1. My Linkedin: https://www.linkedin.com/in/simonliuyuwei/\n",
    "\n",
    "2. InfuseAI: https://infuseai.io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668cc076",
   "metadata": {},
   "source": [
    "### Llama 2\n",
    "\n",
    "The next generation of our open source large language model\n",
    "\n",
    "1. Official Website: [Link](https://ai.meta.com/llama/)\n",
    "\n",
    "2. Download Model: [Link](https://ai.meta.com/resources/models-and-libraries/llama-downloads/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617852d9",
   "metadata": {},
   "source": [
    "### Related Website: \n",
    "\n",
    "1. llama.cpp: [Link](https://github.com/ggerganov/llama.cpp)\n",
    "\n",
    "2. llama-cpp-python: [Link](https://github.com/abetlen/llama-cpp-python)\n",
    "\n",
    "3. ggml: Tensor library for machine learning - [Link](https://github.com/ggerganov/ggml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7a1d72",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd34727e",
   "metadata": {},
   "source": [
    "## Step 1: Install related package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97cf78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU llama-cpp-python\n",
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python --force-reinstall --upgrade --no-cache-dir --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b334357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For download the models\n",
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b617a2d2",
   "metadata": {},
   "source": [
    "## Step 2: Import python libraries and Variable config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bb302a",
   "metadata": {},
   "source": [
    "### Import Python Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c138f0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a79589c",
   "metadata": {},
   "source": [
    "### Configure Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eaa426",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_model_bool = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6e85ad",
   "metadata": {},
   "source": [
    "#### HuggingFace Llama-cpp Model Link:\n",
    "\n",
    "1. TheBloke/Llama-2-7B-chat-GGML: [Link](https://huggingface.co/TheBloke/Llama-2-7B-chat-GGML)\n",
    "2. TheBloke/Llama-2-13B-chat-GGML: [Link](https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML)\n",
    "3. TheBloke/Llama-2-70B-chat-GGML: [Link](https://huggingface.co/TheBloke/Llama-2-70B-chat-GGML)\n",
    "4. audreyt/Taiwan-LLaMa-v1.0-GGML: [Link](https://huggingface.co/audreyt/Taiwan-LLaMa-v1.0-GGML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d430952",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGML\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514dfe3b",
   "metadata": {},
   "source": [
    "#### the model is in bin format:\n",
    "Please Get the bin file from here: https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2657226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_basename = \"llama-2-13b-chat.ggmlv3.q5_1.bin\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54db323",
   "metadata": {},
   "source": [
    "## Step 3: Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920b26e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad8e269",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c2c078",
   "metadata": {},
   "source": [
    "## Step 4: Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62c50a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU\n",
    "lcpp_llm = None\n",
    "lcpp_llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_threads=2,             # CPU cores\n",
    "    n_batch=512,             # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "    n_gpu_layers=32          # Change this value based on your model and your GPU VRAM pool.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c235c196",
   "metadata": {},
   "source": [
    "## Step 5: Create a Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d261b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a linear regression in python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9764a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=f'''SYSTEM: You are a helpful, respectful and honest assistant. Always answer as helpfully.\n",
    "\n",
    "USER: {prompt}\n",
    "\n",
    "ASSISTANT:\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcf7cb2",
   "metadata": {},
   "source": [
    "## Step 6: Generating the Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879a2c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the Result\n",
    "response = lcpp_llm(prompt=prompt_template, max_tokens=256, temperature=0.5, top_p=0.95,\n",
    "                    repeat_penalty=1.2, top_k=150,\n",
    "                    echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6506b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the json content.\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4f367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the response answer.\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
